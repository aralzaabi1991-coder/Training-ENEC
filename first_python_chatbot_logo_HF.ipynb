{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aralzaabi1991-coder/Training-ENEC/blob/main/first_python_chatbot_logo_HF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek3Wj9p-s8P0",
        "outputId": "a2fe192b-f654-4bdb-9785-089c60962990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"openai\")\n"
      ],
      "metadata": {
        "id": "NNsynaFotIn3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "#your system prompt -playground\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "\"Create a Python chatbot that can answer ONLY questions about gold and silver prices. The chatbot should reject or politely refuse to answer any other type of question. Persist in following these requirements for every interaction.\\n\\nWhen generating or evaluating a reply:\\n- First, determine if the user's query is specifically about gold or silver prices.\\n  - Use internal reasoning to decide if the input is about gold/silver prices (e.g., \\\"What's the price of gold?\\\" is valid; \\\"What is bitcoin's price?\\\" is not.)\\n  - If YES: Produce a helpful, accurate, and concise answer about the current or recent price of gold or silver, as appropriate.\\n  - If NO: Respond politely that you can answer only questions about gold and silver prices, and decline to answer any other queries.\\n- NEVER answer non-gold/silver price questions, even if tangential.\\n- For ambiguous or borderline queries, explain that only direct questions about gold or silver prices are accepted and request clarification if needed.\\n\\nOutput Format:\\n- Replies must be plain text. \\n- The response should be 1-3 sentences maximum.\\n\\nReasoning and Conclusion ORDER:\\n- Reason internally (not output to user) whether the query is about gold/silver prices.\\n- Output only the appropriate response as the last step.\\n\\nExamples\\n\\nExample 1  \\nInput: What is the current price of gold?  \\nOutput: The current price of gold is approximately $[CURRENT_GOLD_PRICE] per ounce.\\n\\nExample 2  \\nInput: How much is silver trading for today?  \\nOutput: The current price of silver is about $[CURRENT_SILVER_PRICE] per ounce.\\n\\nExample 3  \\nInput: Tell me a joke.  \\nOutput: I'm sorry, I can only answer questions about gold and silver prices.\\n\\nExample 4  \\nInput: What are the factors affecting gold's value?  \\nOutput: I'm sorry, I can only provide the current prices of gold and silver, not other information.\\n\\nExample 5  \\nInput: What's the price of platinum?  \\nOutput: I'm sorry, I can only answer questions about gold and silver prices.\\n\\n(For real deployment, fill [CURRENT_GOLD_PRICE] and [CURRENT_SILVER_PRICE] with real-time data. The same format applies for all relevant queries.)\\n\\n---\\nReminder: Only answer gold/silver price questions in 1-3 sentence plain text responses; decline all other requests. Reason internally before replying.\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Chatbot ready. Type 'exit' to stop.\")\n",
        "\n",
        "while True:\n",
        "    user_text = input(\"You: \").strip()\n",
        "    if not user_text:\n",
        "        continue\n",
        "    if user_text.lower() in {\"exit\", \"quit\", \"bye\"}:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Add user message\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"input_text\", \"text\": user_text}\n",
        "            ],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Call the Responses API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True,\n",
        "        include=[\"web_search_call.action.sources\"]\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    print(\"Bot:\", assistant_text)\n",
        "\n",
        "    # Store assistant message to preserve context\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"output_text\", \"text\": assistant_text}\n",
        "            ],\n",
        "        }\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQYc8vWHtQP2",
        "outputId": "b7ea2494-8d71-413d-ac41-db35cb8648e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot ready. Type 'exit' to stop.\n",
            "You: where is dubai\n",
            "Bot: I'm sorry, I can only answer questions about gold and silver prices.\n",
            "You: exit\n",
            "Bot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVxgRsVcv9x9",
        "outputId": "853fee41-c6f2-4445-ca36-060a6d6d55e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\"Create a Python chatbot that can answer ONLY questions about gold and silver prices. The chatbot should reject or politely refuse to answer any other type of question. Persist in following these requirements for every interaction.\\n\\nWhen generating or evaluating a reply:\\n- First, determine if the user's query is specifically about gold or silver prices.\\n  - Use internal reasoning to decide if the input is about gold/silver prices (e.g., \\\"What's the price of gold?\\\" is valid; \\\"What is bitcoin's price?\\\" is not.)\\n  - If YES: Produce a helpful, accurate, and concise answer about the current or recent price of gold or silver, as appropriate.\\n  - If NO: Respond politely that you can answer only questions about gold and silver prices, and decline to answer any other queries.\\n- NEVER answer non-gold/silver price questions, even if tangential.\\n- For ambiguous or borderline queries, explain that only direct questions about gold or silver prices are accepted and request clarification if needed.\\n\\nOutput Format:\\n- Replies must be plain text. \\n- The response should be 1-3 sentences maximum.\\n\\nReasoning and Conclusion ORDER:\\n- Reason internally (not output to user) whether the query is about gold/silver prices.\\n- Output only the appropriate response as the last step.\\n\\nExamples\\n\\nExample 1  \\nInput: What is the current price of gold?  \\nOutput: The current price of gold is approximately $[CURRENT_GOLD_PRICE] per ounce.\\n\\nExample 2  \\nInput: How much is silver trading for today?  \\nOutput: The current price of silver is about $[CURRENT_SILVER_PRICE] per ounce.\\n\\nExample 3  \\nInput: Tell me a joke.  \\nOutput: I'm sorry, I can only answer questions about gold and silver prices.\\n\\nExample 4  \\nInput: What are the factors affecting gold's value?  \\nOutput: I'm sorry, I can only provide the current prices of gold and silver, not other information.\\n\\nExample 5  \\nInput: What's the price of platinum?  \\nOutput: I'm sorry, I can only answer questions about gold and silver prices.\\n\\n(For real deployment, fill [CURRENT_GOLD_PRICE] and [CURRENT_SILVER_PRICE] with real-time data. The same format applies for all relevant queries.)\\n\\n---\\nReminder: Only answer gold/silver price questions in 1-3 sentence plain text responses; decline all other requests. Reason internally before replying.\"\n",
        "\"\"\"\n",
        "\n",
        "def init_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def respond(user_text, chat_history, messages):\n",
        "    if messages is None:\n",
        "        messages = init_messages()\n",
        "\n",
        "    # add user turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # call API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    # add assistant turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # update UI chat history\n",
        "    chat_history = chat_history + [(user_text, assistant_text)]\n",
        "\n",
        "    return \"\", chat_history, messages\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Python Chatbot (OpenAI Responses API)\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=420)\n",
        "    msg = gr.Textbox(placeholder=\"Type your Python question and press Enter\")\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    state = gr.State(init_messages())\n",
        "\n",
        "    msg.submit(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    clear.click(\n",
        "        fn=lambda: ([], init_messages()),\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, state]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "Pc8GucSCwGqs",
        "outputId": "16aad597-70c3-4c0f-c902-8923b4ddcd8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2383512617.py:60: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=420)\n",
            "/tmp/ipython-input-2383512617.py:60: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(height=420)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b4e6dd8dd64a7f5c4e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b4e6dd8dd64a7f5c4e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "def init_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def respond(user_text, chat_history, messages):\n",
        "    if messages is None:\n",
        "        messages = init_messages()\n",
        "\n",
        "    # add user turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # call API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    # add assistant turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # update UI chat history\n",
        "    chat_history = chat_history + [(user_text, assistant_text)]\n",
        "\n",
        "    return \"\", chat_history, messages\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Gradio UI (Upgraded)\n",
        "# -----------------------------\n",
        "\n",
        "FAQ_QUESTIONS = [\n",
        "    \"What is the difference between a list, tuple, and set in Python?\",\n",
        "    \"How do I use dictionaries effectively in Python?\",\n",
        "    \"What are Python functions and how do *args and **kwargs work?\",\n",
        "    \"How does OOP work in Python (classes, objects, inheritance)?\",\n",
        "    \"How do I handle errors using try/except?\",\n",
        "    \"What are list comprehensions and when should I use them?\",\n",
        "    \"How do I read and write files in Python?\"\n",
        "]\n",
        "\n",
        "def set_question(q):\n",
        "    return q\n",
        "\n",
        "def clear_all():\n",
        "    return [], init_messages(), \"\"\n",
        "\n",
        "css = \"\"\"\n",
        "/* Overall spacing + subtle polish */\n",
        "#app_container {max-width: 1200px; margin: 0 auto;}\n",
        "\n",
        "/* Header styling */\n",
        ".header-wrap {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    gap: 14px;\n",
        "    padding: 10px 6px 2px 6px;\n",
        "}\n",
        ".header-title {\n",
        "    font-size: 28px;\n",
        "    font-weight: 700;\n",
        "    line-height: 1.1;\n",
        "}\n",
        ".header-subtitle {\n",
        "    font-size: 12.5px;\n",
        "    opacity: 0.75;\n",
        "    margin-top: 2px;\n",
        "}\n",
        "\n",
        "/* FAQ card-like feel */\n",
        ".faq-box {\n",
        "    border: 1px solid rgba(255,255,255,0.08);\n",
        "    border-radius: 12px;\n",
        "    padding: 14px;\n",
        "}\n",
        "\n",
        "/* Make buttons full width in FAQ column */\n",
        ".faq-btn button {\n",
        "    width: 100%;\n",
        "    justify-content: flex-start;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
        "    # Header Row\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=80):\n",
        "            # Use your local file path or URL\n",
        "            logo = gr.Image(\n",
        "                value=\"https://github.com/Decoding-Data-Science/nov25/blob/main/logo_python.png\",\n",
        "                label=None,\n",
        "                show_label=False,\n",
        "                show_download_button=False,\n",
        "                show_share_button=False,\n",
        "                height=64,\n",
        "                width=64,\n",
        "                container=False\n",
        "            )\n",
        "        with gr.Column(scale=10):\n",
        "            gr.HTML(\n",
        "                \"\"\"\n",
        "                <div class=\"header-wrap\">\n",
        "                    <div>\n",
        "                        <div class=\"header-title\">Python Tutor Bot</div>\n",
        "                        <div class=\"header-subtitle\">\n",
        "                            Ask anything about Python — concepts, debugging, best practices, and examples.\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "\n",
        "    # State (unchanged logic)\n",
        "    state = gr.State(init_messages())\n",
        "\n",
        "    # Two-column layout\n",
        "    with gr.Row(equal_height=True):\n",
        "        # LEFT: FAQ + Quick Ask\n",
        "        with gr.Column(scale=4, min_width=320):\n",
        "            with gr.Group(elem_classes=[\"faq-box\"]):\n",
        "                gr.Markdown(\"### FAQ — Most Asked Python Questions\")\n",
        "\n",
        "                gr.Markdown(\n",
        "                    \"Click a question to auto-fill it, then press **Enter** or click **Send**.\"\n",
        "                )\n",
        "\n",
        "                # Buttons for FAQ\n",
        "                faq_buttons = []\n",
        "                for q in FAQ_QUESTIONS:\n",
        "                    b = gr.Button(q, elem_classes=[\"faq-btn\"])\n",
        "                    faq_buttons.append(b)\n",
        "\n",
        "                gr.Markdown(\"### Quick prompt ideas\")\n",
        "                quick = gr.Radio(\n",
        "                    choices=[\n",
        "                        \"Explain with a simple example\",\n",
        "                        \"Give me a beginner-friendly analogy\",\n",
        "                        \"Show common mistakes to avoid\",\n",
        "                        \"Provide a short quiz question\",\n",
        "                        \"Compare two approaches briefly\"\n",
        "                    ],\n",
        "                    label=\"Add a style preference (optional)\",\n",
        "                    value=None\n",
        "                )\n",
        "\n",
        "        # RIGHT: Chat area\n",
        "        with gr.Column(scale=8, min_width=520):\n",
        "            chatbot = gr.Chatbot(\n",
        "                height=520,\n",
        "                bubble_full_width=False,\n",
        "                label=\"Conversation\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    placeholder=\"Type your Python question here…\",\n",
        "                    label=None,\n",
        "                    scale=9\n",
        "                )\n",
        "                send = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear = gr.Button(\"Clear Chat\")\n",
        "                gr.Markdown(\n",
        "                    \"<span style='opacity:0.7;font-size:12px;'>Context is preserved across turns unless you clear.</span>\"\n",
        "                )\n",
        "\n",
        "    # FAQ button -> fill textbox\n",
        "    for b, q in zip(faq_buttons, FAQ_QUESTIONS):\n",
        "        b.click(\n",
        "            fn=lambda q=q: set_question(q),\n",
        "            inputs=None,\n",
        "            outputs=msg\n",
        "        )\n",
        "\n",
        "    # Optional quick preference: append hint to textbox (UI-only)\n",
        "    def apply_quick_pref(pref, current_text):\n",
        "        if not pref:\n",
        "            return current_text\n",
        "        if current_text and current_text.strip():\n",
        "            return f\"{current_text.strip()} ({pref})\"\n",
        "        return pref\n",
        "\n",
        "    quick.change(\n",
        "        fn=apply_quick_pref,\n",
        "        inputs=[quick, msg],\n",
        "        outputs=msg\n",
        "    )\n",
        "\n",
        "    # Submit logic (unchanged)\n",
        "    msg.submit(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    send.click(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    # Clear\n",
        "    clear.click(\n",
        "        fn=clear_all,\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, state, msg]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "Lw5NgVBo-R6M",
        "outputId": "caf87e85-ac86-4b1e-fc43-1c05e5362c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-848837234.py:146: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
            "/tmp/ipython-input-848837234.py:146: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
            "/tmp/ipython-input-848837234.py:212: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-848837234.py:212: DeprecationWarning: The 'bubble_full_width' parameter will be removed in Gradio 6.0. This parameter no longer has any effect.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-848837234.py:212: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://08b8d5896369f9d38f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://08b8d5896369f9d38f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# RAW GitHub URL so it renders correctly\n",
        "LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/nov25/main/logo_python.png\"\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "def build_initial_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def chat_fn(user_message, history, messages_state):\n",
        "    if messages_state is None:\n",
        "        messages_state = build_initial_messages()\n",
        "\n",
        "    # Add user message to state\n",
        "    messages_state.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_message}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Call Responses API\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages_state,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_message = resp.output_text\n",
        "\n",
        "    # Add assistant message to state\n",
        "    messages_state.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_message}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Update visible chat\n",
        "    history = history + [(user_message, assistant_message)]\n",
        "\n",
        "    return \"\", history, messages_state\n",
        "\n",
        "def reset_chat():\n",
        "    return [], build_initial_messages()\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    # Header with logo at native size (no width/height restriction)\n",
        "    gr.Markdown(\n",
        "        f\"\"\"\n",
        "<div style=\"display:flex; align-items:center; gap:12px;\">\n",
        "  <img src=\"{LOGO_URL}\" />\n",
        "  <div>\n",
        "    <div style=\"font-size:22px; font-weight:600;\">Python Chatbot</div>\n",
        "    <div style=\"font-size:13px; opacity:0.8;\">Powered by OpenAI Responses API</div>\n",
        "  </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    chatbot = gr.Chatbot(height=420)\n",
        "\n",
        "    input_box = gr.Textbox(\n",
        "        placeholder=\"Type your Python question and press Enter\",\n",
        "        show_label=False\n",
        "    )\n",
        "\n",
        "    clear_btn = gr.Button(\"Clear\")\n",
        "\n",
        "    messages_state = gr.State(build_initial_messages())\n",
        "\n",
        "    input_box.submit(\n",
        "        fn=chat_fn,\n",
        "        inputs=[input_box, chatbot, messages_state],\n",
        "        outputs=[input_box, chatbot, messages_state]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=reset_chat,\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, messages_state]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "5MSnC8L4_nLC",
        "outputId": "6fcfd81c-cca3-44bb-cc82-ee341cfb1a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2076293516.py:109: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=420)\n",
            "/tmp/ipython-input-2076293516.py:109: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(height=420)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8dc6bcec5994819bf8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8dc6bcec5994819bf8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# Use the RAW GitHub URL so the image loads correctly\n",
        "LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/nov25/main/logo_python.png\"\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "def build_initial_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def chat_fn(user_message, history, messages_state):\n",
        "    # Initialize state if needed\n",
        "    if messages_state is None:\n",
        "        messages_state = build_initial_messages()\n",
        "\n",
        "    # Append user input\n",
        "    messages_state.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_message}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Call Responses API\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages_state,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_message = resp.output_text\n",
        "\n",
        "    # Append assistant output\n",
        "    messages_state.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_message}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Update visible chat history\n",
        "    history = history + [(user_message, assistant_message)]\n",
        "\n",
        "    # Clear textbox, update chat + state\n",
        "    return \"\", history, messages_state\n",
        "\n",
        "def reset_chat():\n",
        "    return [], build_initial_messages()\n",
        "\n",
        "css = \"\"\"\n",
        "/* Overall app container styling */\n",
        "#app_container {\n",
        "    max-width: 1200px;\n",
        "    margin: 0 auto;\n",
        "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "    background: linear-gradient(135deg, #1e1e2f, #2e2e4a); /* Dark blue-purple gradient background */\n",
        "    color: #e0e0e0; /* Light text color for general content */\n",
        "    border-radius: 15px;\n",
        "    box-shadow: 0 8px 30px rgba(0, 0, 0, 0.4);\n",
        "    overflow: hidden; /* Ensures background gradient is contained */\n",
        "}\n",
        "\n",
        "/* Header styling */\n",
        ".header-wrap {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    gap: 15px;\n",
        "    padding: 20px 25px;\n",
        "    background-color: rgba(0, 0, 0, 0.3); /* Slightly transparent dark background */\n",
        "    border-bottom: 1px solid rgba(255, 255, 255, 0.1);\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        ".header-title {\n",
        "    font-size: 32px;\n",
        "    font-weight: 700;\n",
        "    line-height: 1.2;\n",
        "    color: #a0e0ff; /* Bright blue for title */\n",
        "    text-shadow: 1px 1px 3px rgba(0,0,0,0.5);\n",
        "}\n",
        ".header-subtitle {\n",
        "    font-size: 14px;\n",
        "    opacity: 0.85;\n",
        "    margin-top: 5px;\n",
        "    color: #c0d0f0;\n",
        "}\n",
        "\n",
        "/* FAQ card-like feel */\n",
        ".faq-box {\n",
        "    border: 1px solid rgba(255,255,255,0.1);\n",
        "    border-radius: 12px;\n",
        "    padding: 18px;\n",
        "    background-color: rgba(0, 0, 0, 0.2);\n",
        "    box-shadow: 0 4px 15px rgba(0,0,0,0.3);\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        "\n",
        "/* Make buttons full width in FAQ column */\n",
        ".faq-btn button {\n",
        "    width: 100%;\n",
        "    justify-content: flex-start;\n",
        "    background-color: #3a3a5a; /* Darker blue-purple button */\n",
        "    color: #f0f0f0;\n",
        "    border: none;\n",
        "    border-radius: 8px;\n",
        "    padding: 12px 15px;\n",
        "    margin-bottom: 8px;\n",
        "    transition: background-color 0.2s ease;\n",
        "}\n",
        ".faq-btn button:hover {\n",
        "    background-color: #4a4a7a;\n",
        "    transform: translateY(-1px);\n",
        "}\n",
        "\n",
        "/* Markdown Separator */\n",
        "hr {\n",
        "    border-top: 1px solid rgba(255, 255, 255, 0.1);\n",
        "    margin: 25px 0;\n",
        "}\n",
        "\n",
        "/* Chat area styling */\n",
        ".gradio-chatbot {\n",
        "    border: 1px solid rgba(255,255,255,0.1);\n",
        "    border-radius: 12px;\n",
        "    background-color: rgba(0, 0, 0, 0.15); /* Slightly transparent for depth */\n",
        "    min-height: 520px; /* Ensure consistent height */\n",
        "}\n",
        "\n",
        "/* Input/Send controls */\n",
        ".gradio-row {\n",
        "    margin-top: 15px;\n",
        "}\n",
        "\n",
        "/* Textbox styling */\n",
        ".gradio-textbox textarea {\n",
        "    background-color: #2a2a40; /* Dark input field */\n",
        "    color: #e0e0e0;\n",
        "    border: 1px solid #4a4a6a;\n",
        "    border-radius: 8px;\n",
        "    padding: 10px;\n",
        "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.3);\n",
        "}\n",
        ".gradio-textbox textarea:focus {\n",
        "    border-color: #a0e0ff;\n",
        "    box-shadow: 0 0 0 2px rgba(160, 224, 255, 0.3);\n",
        "}\n",
        "\n",
        "/* Send button styling */\n",
        ".gradio-button.primary {\n",
        "    background: linear-gradient(45deg, #007bff, #00c0ff); /* Blue gradient for send */\n",
        "    border: none;\n",
        "    border-radius: 8px;\n",
        "    color: white;\n",
        "    font-weight: 600;\n",
        "    transition: all 0.2s ease;\n",
        "}\n",
        ".gradio-button.primary:hover {\n",
        "    background: linear-gradient(45deg, #0056b3, #009be6);\n",
        "    transform: translateY(-2px);\n",
        "    box-shadow: 0 4px 10px rgba(0,0,0,0.3);\n",
        "}\n",
        "\n",
        "/* Clear button styling */\n",
        ".gradio-button {\n",
        "    background-color: #dc3545; /* Red for clear */\n",
        "    border: none;\n",
        "    border-radius: 8px;\n",
        "    color: white;\n",
        "    font-weight: 600;\n",
        "    transition: all 0.2s ease;\n",
        "}\n",
        ".gradio-button:hover {\n",
        "    background-color: #c82333;\n",
        "    transform: translateY(-2px);\n",
        "    box-shadow: 0 4px 10px rgba(0,0,0,0.3);\n",
        "}\n",
        "\n",
        "/* Small text at bottom */\n",
        "span[style*='opacity:0.7'] {\n",
        "    color: #b0b0d0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
        "    # Header with combined logo and text using CSS classes\n",
        "    gr.HTML(\n",
        "        f\"\"\"\n",
        "        <div class=\"header-wrap\">\n",
        "            <img src=\"{LOGO_URL}\" alt=\"Python Logo\" style=\"height:64px; width:64px; object-fit: contain; border-radius: 8px;\">\n",
        "            <div>\n",
        "                <div class=\"header-title\">Python Tutor Bot</div>\n",
        "                <div class=\"header-subtitle\">\n",
        "                    Ask anything about Python — concepts, debugging, best practices, and examples.\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"___\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=420)\n",
        "    input_box = gr.Textbox(\n",
        "        placeholder=\"Type your Python question and press Enter\",\n",
        "        show_label=False\n",
        "    )\n",
        "    clear_btn = gr.Button(\"Clear\")\n",
        "\n",
        "    messages_state = gr.State(build_initial_messages())\n",
        "\n",
        "    input_box.submit(\n",
        "        fn=chat_fn,\n",
        "        inputs=[input_box, chatbot, messages_state],\n",
        "        outputs=[input_box, chatbot, messages_state]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=reset_chat,\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, messages_state]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "J6dUI_eJ_6rh",
        "outputId": "cf13a46f-bbca-4737-b8cb-021a9031fb73"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3013770024.py:230: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
            "/tmp/ipython-input-3013770024.py:230: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
            "/tmp/ipython-input-3013770024.py:248: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=420)\n",
            "/tmp/ipython-input-3013770024.py:248: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(height=420)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://32c12121787114b455.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://32c12121787114b455.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "def init_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def respond(user_text, chat_history, messages):\n",
        "    if messages is None:\n",
        "        messages = init_messages()\n",
        "\n",
        "    # add user turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # call API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    # add assistant turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # update UI chat history\n",
        "    chat_history = chat_history + [(user_text, assistant_text)]\n",
        "\n",
        "    return \"\", chat_history, messages\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Gradio UI (Upgraded)\n",
        "# -----------------------------\n",
        "\n",
        "FAQ_QUESTIONS = [\n",
        "    \"What is the difference between a list, tuple, and set in Python?\",\n",
        "    \"How do I use dictionaries effectively in Python?\",\n",
        "    \"What are Python functions and how do *args and **kwargs work?\",\n",
        "    \"How does OOP work in Python (classes, objects, inheritance)?\",\n",
        "    \"How do I handle errors using try/except?\",\n",
        "    \"What are list comprehensions and when should I use them?\",\n",
        "    \"How do I read and write files in Python?\"\n",
        "]\n",
        "\n",
        "def set_question(q):\n",
        "    return q\n",
        "\n",
        "def clear_all():\n",
        "    return [], init_messages(), \"\"\n",
        "\n",
        "# Updated logo URL (RAW link)\n",
        "LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/nov25/main/logo_python.png\"\n",
        "\n",
        "css = \"\"\"\n",
        "/* Overall spacing + subtle polish */\n",
        "#app_container {max-width: 1200px; margin: 0 auto;}\n",
        "\n",
        "/* Header styling */\n",
        ".header-wrap {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    gap: 14px;\n",
        "    padding: 10px 6px 2px 6px;\n",
        "}\n",
        ".header-title {\n",
        "    font-size: 28px;\n",
        "    font-weight: 700;\n",
        "    line-height: 1.1;\n",
        "}\n",
        ".header-subtitle {\n",
        "    font-size: 12.5px;\n",
        "    opacity: 0.75;\n",
        "    margin-top: 2px;\n",
        "}\n",
        "\n",
        "/* FAQ card-like feel */\n",
        ".faq-box {\n",
        "    border: 1px solid rgba(255,255,255,0.08);\n",
        "    border-radius: 12px;\n",
        "    padding: 14px;\n",
        "}\n",
        "\n",
        "/* Make buttons full width in FAQ column */\n",
        ".faq-btn button {\n",
        "    width: 100%;\n",
        "    justify-content: flex-start;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
        "    # Header Row\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=80):\n",
        "            logo = gr.Image(\n",
        "                value=LOGO_URL,  # ✅ updated to raw URL\n",
        "                label=None,\n",
        "                show_label=False,\n",
        "                show_download_button=False,\n",
        "                show_share_button=False,\n",
        "                height=64,\n",
        "                width=64,\n",
        "                container=False\n",
        "            )\n",
        "        with gr.Column(scale=10):\n",
        "            gr.HTML(\n",
        "                \"\"\"\n",
        "                <div class=\"header-wrap\">\n",
        "                    <div>\n",
        "                        <div class=\"header-title\">Python Tutor Bot</div>\n",
        "                        <div class=\"header-subtitle\">\n",
        "                            Ask anything about Python — concepts, debugging, best practices, and examples.\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "\n",
        "    # State (unchanged logic)\n",
        "    state = gr.State(init_messages())\n",
        "\n",
        "    # Two-column layout\n",
        "    with gr.Row(equal_height=True):\n",
        "        # LEFT: FAQ + Quick Ask\n",
        "        with gr.Column(scale=4, min_width=320):\n",
        "            with gr.Group(elem_classes=[\"faq-box\"]):\n",
        "                gr.Markdown(\"### FAQ — Most Asked Python Questions\")\n",
        "\n",
        "                gr.Markdown(\n",
        "                    \"Click a question to auto-fill it, then press **Enter** or click **Send**.\"\n",
        "                )\n",
        "\n",
        "                # Buttons for FAQ\n",
        "                faq_buttons = []\n",
        "                for q in FAQ_QUESTIONS:\n",
        "                    b = gr.Button(q, elem_classes=[\"faq-btn\"])\n",
        "                    faq_buttons.append(b)\n",
        "\n",
        "                gr.Markdown(\"### Quick prompt ideas\")\n",
        "                quick = gr.Radio(\n",
        "                    choices=[\n",
        "                        \"Explain with a simple example\",\n",
        "                        \"Give me a beginner-friendly analogy\",\n",
        "                        \"Show common mistakes to avoid\",\n",
        "                        \"Provide a short quiz question\",\n",
        "                        \"Compare two approaches briefly\"\n",
        "                    ],\n",
        "                    label=\"Add a style preference (optional)\",\n",
        "                    value=None\n",
        "                )\n",
        "\n",
        "        # RIGHT: Chat area\n",
        "        with gr.Column(scale=8, min_width=520):\n",
        "            chatbot = gr.Chatbot(\n",
        "                height=520,\n",
        "                bubble_full_width=False,\n",
        "                label=\"Conversation\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    placeholder=\"Type your Python question here…\",\n",
        "                    label=None,\n",
        "                    scale=9\n",
        "                )\n",
        "                send = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear = gr.Button(\"Clear Chat\")\n",
        "                gr.Markdown(\n",
        "                    \"<span style='opacity:0.7;font-size:12px;'>Context is preserved across turns unless you clear.</span>\"\n",
        "                )\n",
        "\n",
        "    # FAQ button -> fill textbox\n",
        "    for b, q in zip(faq_buttons, FAQ_QUESTIONS):\n",
        "        b.click(\n",
        "            fn=lambda q=q: set_question(q),\n",
        "            inputs=None,\n",
        "            outputs=msg\n",
        "        )\n",
        "\n",
        "    # Optional quick preference: append hint to textbox (UI-only)\n",
        "    def apply_quick_pref(pref, current_text):\n",
        "        if not pref:\n",
        "            return current_text\n",
        "        if current_text and current_text.strip():\n",
        "            return f\"{current_text.strip()} ({pref})\"\n",
        "        return pref\n",
        "\n",
        "    quick.change(\n",
        "        fn=apply_quick_pref,\n",
        "        inputs=[quick, msg],\n",
        "        outputs=msg\n",
        "    )\n",
        "\n",
        "    # Submit logic (unchanged)\n",
        "    msg.submit(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    send.click(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    # Clear\n",
        "    clear.click(\n",
        "        fn=clear_all,\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, state, msg]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "pJ7OLyxcAZTS",
        "outputId": "97bedde9-3726-4ffd-f06e-92fd0f970b1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1706520990.py:149: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
            "/tmp/ipython-input-1706520990.py:149: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
            "/tmp/ipython-input-1706520990.py:214: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-1706520990.py:214: DeprecationWarning: The 'bubble_full_width' parameter will be removed in Gradio 6.0. This parameter no longer has any effect.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-1706520990.py:214: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1c8bc800b8105436c3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1c8bc800b8105436c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Steps to deploy on Hugging Face Spaces (Gradio)\n",
        "\n",
        "Hugging Face → New Space\n",
        "\n",
        "Choose Gradio as SDK. This sets your Space to use Gradio via the README config.\n",
        "Hugging Face\n",
        "\n",
        "Pick a name and visibility.\n",
        "\n",
        "Add files\n",
        "1. app.py (your code).\n",
        "\n",
        "2. requirements.txt.\n",
        "\n",
        "requirements.txt\n",
        "Use something like:\n",
        "\n",
        "gradio\n",
        "openai\n",
        "\n",
        "\n",
        "##Add your secret\n",
        "\n",
        "Go to your Space Settings → Variables and secrets.\n",
        "\n",
        "Under Secrets, add:\n",
        "\n",
        "Name: OPENAI_API_KEY\n",
        "\n",
        "Value: your key\n",
        "Secrets are injected into the runtime as environment variables.\n",
        "Hugging Face\n",
        "\n",
        "\n",
        "Commit\n",
        "\n",
        "If you’re editing in the browser, just save/commit.\n",
        "\n",
        "The Space will rebuild and launch automatically."
      ],
      "metadata": {
        "id": "h37xxhJLhvl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ADD THIS IN APP.PY\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "# -----------------------------\n",
        "# Load OpenAI key from HF Secrets\n",
        "# -----------------------------\n",
        "# In Hugging Face Spaces, Secrets/Variables are available as environment variables.\n",
        "# Add this in your Space Settings -> Variables and secrets -> Secrets\n",
        "# Key name: OPENAI_API_KEY\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "def init_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def respond(user_text, chat_history, messages):\n",
        "    if messages is None:\n",
        "        messages = init_messages()\n",
        "\n",
        "    # add user turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # call API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    # add assistant turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # update UI chat history\n",
        "    chat_history = chat_history + [(user_text, assistant_text)]\n",
        "\n",
        "    return \"\", chat_history, messages\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Gradio UI (Upgraded)\n",
        "# -----------------------------\n",
        "\n",
        "FAQ_QUESTIONS = [\n",
        "    \"What is the difference between a list, tuple, and set in Python?\",\n",
        "    \"How do I use dictionaries effectively in Python?\",\n",
        "    \"What are Python functions and how do *args and **kwargs work?\",\n",
        "    \"How does OOP work in Python (classes, objects, inheritance)?\",\n",
        "    \"How do I handle errors using try/except?\",\n",
        "    \"What are list comprehensions and when should I use them?\",\n",
        "    \"How do I read and write files in Python?\"\n",
        "]\n",
        "\n",
        "def set_question(q):\n",
        "    return q\n",
        "\n",
        "def clear_all():\n",
        "    return [], init_messages(), \"\"\n",
        "\n",
        "# Updated logo URL (RAW link)\n",
        "LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/nov25/main/logo_python.png\"\n",
        "\n",
        "css = \"\"\"\n",
        "/* Overall spacing + subtle polish */\n",
        "#app_container {max-width: 1200px; margin: 0 auto;}\n",
        "\n",
        "/* Header styling */\n",
        ".header-wrap {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    gap: 14px;\n",
        "    padding: 10px 6px 2px 6px;\n",
        "}\n",
        ".header-title {\n",
        "    font-size: 28px;\n",
        "    font-weight: 700;\n",
        "    line-height: 1.1;\n",
        "}\n",
        ".header-subtitle {\n",
        "    font-size: 12.5px;\n",
        "    opacity: 0.75;\n",
        "    margin-top: 2px;\n",
        "}\n",
        "\n",
        "/* FAQ card-like feel */\n",
        ".faq-box {\n",
        "    border: 1px solid rgba(255,255,255,0.08);\n",
        "    border-radius: 12px;\n",
        "    padding: 14px;\n",
        "}\n",
        "\n",
        "/* Make buttons full width in FAQ column */\n",
        ".faq-btn button {\n",
        "    width: 100%;\n",
        "    justify-content: flex-start;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css, theme=gr.themes.Soft(), elem_id=\"app_container\") as demo:\n",
        "    # Header Row\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=80):\n",
        "            logo = gr.Image(\n",
        "                value=LOGO_URL,\n",
        "                label=None,\n",
        "                show_label=False,\n",
        "                show_download_button=False,\n",
        "                show_share_button=False,\n",
        "                height=64,\n",
        "                width=64,\n",
        "                container=False\n",
        "            )\n",
        "        with gr.Column(scale=10):\n",
        "            gr.HTML(\n",
        "                \"\"\"\n",
        "                <div class=\"header-wrap\">\n",
        "                    <div>\n",
        "                        <div class=\"header-title\">Python Tutor Bot</div>\n",
        "                        <div class=\"header-subtitle\">\n",
        "                            Ask anything about Python — concepts, debugging, best practices, and examples.\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "\n",
        "    # State (unchanged logic)\n",
        "    state = gr.State(init_messages())\n",
        "\n",
        "    # Two-column layout\n",
        "    with gr.Row(equal_height=True):\n",
        "        # LEFT: FAQ + Quick Ask\n",
        "        with gr.Column(scale=4, min_width=320):\n",
        "            with gr.Group(elem_classes=[\"faq-box\"]):\n",
        "                gr.Markdown(\"### FAQ — Most Asked Python Questions\")\n",
        "\n",
        "                gr.Markdown(\n",
        "                    \"Click a question to auto-fill it, then press **Enter** or click **Send**.\"\n",
        "                )\n",
        "\n",
        "                # Buttons for FAQ\n",
        "                faq_buttons = []\n",
        "                for q in FAQ_QUESTIONS:\n",
        "                    b = gr.Button(q, elem_classes=[\"faq-btn\"])\n",
        "                    faq_buttons.append(b)\n",
        "\n",
        "                gr.Markdown(\"### Quick prompt ideas\")\n",
        "                quick = gr.Radio(\n",
        "                    choices=[\n",
        "                        \"Explain with a simple example\",\n",
        "                        \"Give me a beginner-friendly analogy\",\n",
        "                        \"Show common mistakes to avoid\",\n",
        "                        \"Provide a short quiz question\",\n",
        "                        \"Compare two approaches briefly\"\n",
        "                    ],\n",
        "                    label=\"Add a style preference (optional)\",\n",
        "                    value=None\n",
        "                )\n",
        "\n",
        "        # RIGHT: Chat area\n",
        "        with gr.Column(scale=8, min_width=520):\n",
        "            chatbot = gr.Chatbot(\n",
        "                height=520,\n",
        "                bubble_full_width=False,\n",
        "                label=\"Conversation\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    placeholder=\"Type your Python question here…\",\n",
        "                    label=None,\n",
        "                    scale=9\n",
        "                )\n",
        "                send = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear = gr.Button(\"Clear Chat\")\n",
        "                gr.Markdown(\n",
        "                    \"<span style='opacity:0.7;font-size:12px;'>Context is preserved across turns unless you clear.</span>\"\n",
        "                )\n",
        "\n",
        "    # FAQ button -> fill textbox\n",
        "    for b, q in zip(faq_buttons, FAQ_QUESTIONS):\n",
        "        b.click(\n",
        "            fn=lambda q=q: set_question(q),\n",
        "            inputs=None,\n",
        "            outputs=msg\n",
        "        )\n",
        "\n",
        "    # Optional quick preference: append hint to textbox (UI-only)\n",
        "    def apply_quick_pref(pref, current_text):\n",
        "        if not pref:\n",
        "            return current_text\n",
        "        if current_text and current_text.strip():\n",
        "            return f\"{current_text.strip()} ({pref})\"\n",
        "        return pref\n",
        "\n",
        "    quick.change(\n",
        "        fn=apply_quick_pref,\n",
        "        inputs=[quick, msg],\n",
        "        outputs=msg\n",
        "    )\n",
        "\n",
        "    # Submit logic (unchanged)\n",
        "    msg.submit(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    send.click(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    # Clear\n",
        "    clear.click(\n",
        "        fn=clear_all,\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, state, msg]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "id": "ETjWIY-PheDe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}