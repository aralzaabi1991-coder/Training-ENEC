{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aralzaabi1991-coder/Training-ENEC/blob/main/first_python_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek3Wj9p-s8P0",
        "outputId": "01a43e21-6b2c-495e-97af-68bcb0173448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"openai\")\n"
      ],
      "metadata": {
        "id": "NNsynaFotIn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Chatbot ready. Type 'exit' to stop.\")\n",
        "\n",
        "while True:\n",
        "    user_text = input(\"You: \").strip()\n",
        "    if not user_text:\n",
        "        continue\n",
        "    if user_text.lower() in {\"exit\", \"quit\", \"bye\"}:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Add user message\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"input_text\", \"text\": user_text}\n",
        "            ],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Call the Responses API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True,\n",
        "        include=[\"web_search_call.action.sources\"]\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    print(\"Bot:\", assistant_text)\n",
        "\n",
        "    # Store assistant message to preserve context\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"output_text\", \"text\": assistant_text}\n",
        "            ],\n",
        "        }\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQYc8vWHtQP2",
        "outputId": "b244e27e-065f-454c-93b5-3919d15ad898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot ready. Type 'exit' to stop.\n",
            "You: What is tuple?\n",
            "Bot: A tuple in Python is an ordered, immutable collection of items, meaning once it’s created, its contents can’t be changed. You can store different data types in a tuple, like numbers, strings, or even other tuples. For example, you could define one as my_tuple = (1, \"apple\", 3.5). Would you like me to explain how tuples differ from lists?\n",
            "You: exit\n",
            "Bot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVxgRsVcv9x9",
        "outputId": "e8c7f308-6c67-4dc9-974e-30d10c738e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "def init_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def respond(user_text, chat_history, messages):\n",
        "    if messages is None:\n",
        "        messages = init_messages()\n",
        "\n",
        "    # add user turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # call API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    # add assistant turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # update UI chat history\n",
        "    chat_history = chat_history + [(user_text, assistant_text)]\n",
        "\n",
        "    return \"\", chat_history, messages\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Python Chatbot (OpenAI Responses API)\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=420)\n",
        "    msg = gr.Textbox(placeholder=\"Type your Python question and press Enter\")\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    state = gr.State(init_messages())\n",
        "\n",
        "    msg.submit(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    clear.click(\n",
        "        fn=lambda: ([], init_messages()),\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, state]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Pc8GucSCwGqs",
        "outputId": "ad917cc3-16af-41fa-b143-9192de07dad8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3281300874.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    }
  ]
}